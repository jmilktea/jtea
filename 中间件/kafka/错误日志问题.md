本篇分享一个生产环境的kafka消费者经常报错，打印error日志的例子。  
报错的信息如下：    
![image]()      

这些错误每天都会有，经常触发告警。但实际上消息是被正常消费掉的，也就是后面自动重试消费成功了。   
报错一般是一些消息量比较大的topic，而且经常是在某个时间节点当大量产生消息时，消费者打印了上面的错误。   
我们的客户端使用的是spring-kafka，它是对apache kafka client的封装。开始排查到github上尝试搜索关键词，如：This is not the correct coordinator   
找到一些类似的回复，如：   
![image]()        

这里涉及到两个参数：  
max.poll.records：每次拉取的数量，默认是500     
max.poll.interval.ms：每次拉取的时间间隔，默认是300s   

文中的意思是我们的消费速度太慢，导致触发rebalance，尝试减少每次拉取的数量和加大每次拉取的时间间隔，让消费者可以有时间消费完。   
开始我们对此进行优化，让代码执行得更快一些，而且加大了消费线程，并发消费，如：  
```
@KafkaListener(topics = "test_topic",concurrency = "5")
```
可是一顿操作下来，有一点点好转，但是不明显，错误日志依旧在打印，告警依然在产生...     

尝试过一段时间的google,百度之后，发现很难描述，找不到正确答案，每天看到一堆错误日志和群里的告警实在不爽。    
既然这个错是可以自动恢复的，也就是这个日志其实不那么重要，我们不太关心，那是不是可以把这些日志忽略了就可以了呢？   
我们找到打印日志的地方，使用logback配置如下：  
```
logging:
  level:  
    org.apache.kafka.clients.consumer.internals.ConsumerCoordinator: off
```
这样做就能把打印error的这个类关闭日志的打印，但总感觉不是很优雅，因为这样就关闭了所有日志，如果是正常需要打印的，也会一并被关闭。   

许久之后...，上面我们说到spring-kafka实际是对apache kafka client的一个封装，那么我尝试去apache kafka的issues上搜索终于有所发现：  
https://issues.apache.org/jira/browse/KAFKA-8334?jql=project%20%3D%20KAFKA%20AND%20text%20~%20%22Offset%20commit%20failed%20on%20partition%22
![image]()  
这个描述和我们出现的问题是一致的。文中主要的意思是这些错误是可重试的，不应该被当做error日志打印，主要会影响程序的判断。   
类似的描述还有这里：  
https://issues.apache.org/jira/browse/KAFKA-7791   
![image]()   

图中还提到几种不应该打印的日志，并且有一个github的mr：https://github.com/apache/kafka/pull/5904   
这个mr非常简单，就是在打印日志的地方判断一下是不是可重试的异常，如果是就打印warn，否则打印error。  
![image]()   

我们看到这个mr已经被接受合并到主分支。但是我们的程序确实没有，这基本可以确定是版本问题了，发现我们使用的spring-kafka版本比较低，对应的kafka-client也比较低，
升级后即可，问题解决，再也不会出现告警了~  
![image]()  

